# 5G 과제 1차년도



## 사용 툴 버전

- ubuntu : 18.04
- python 3.7.6
- kubernetes : 1.14
- docker : 19.03.12 
- Prometheus  : 최신버전
- Grafana : 최신버전
- OpenCV : 
- VLC
- RTSP
- Flask : 1.0.2



## 프로그램 설치 프로세스



### 1. Docker

#### 준비

- apt update

  ```bash
  sudo apt-get update
  ```

- 오래된 버전 도커 삭제

  ```bash
  sudo apt-get remove docker docker-engine docker.io
  ```

- 패키지 설치

  ```
  sudo apt-get update && sudo apt-get install \
      apt-transport-https \
      ca-certificates \
      curl \
      software-properties-common
  ```

  

#### 패키지 저장소 추가

- 도커의 공식 gpg 키와 저장소 추가

  ```bash
  # 공식 gpg 키 추가
  $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
  # 공식 키 확인
  $ sudo apt-key fingerprint 0EBFCD88
  # 저장소 추가
  $ sudo add-apt-repository \
     "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
     bionic \
     stable"
  # docker 패키지 검색되는지 확인
  $ sudo apt-get update 
  $ sudo apt-cache search docker-ce
  ## 출력메시지
  docker-ce - Docker: the open-source application container engine
  ```

  

#### 도커 CE설치

```bash
$ sudo apt-get update 
$ sudo apt-get install docker-ce

# 사용자를 docker 그룹에 추가
$ sudo usermod -aG docker $USER
```



#### 반드시 스왑 메모리 비활성화

```
sudo swapoff -a
```



#### 도커 데몬 드라이버 교체

- from `cgroupfs` to `systemd`

  ```bash
  $ sudo cat > /etc/docker/daemon.json <<EOF
  {
    "exec-opts": ["native.cgroupdriver=systemd"],
    "log-driver": "json-file",
    "log-opts": {
      "max-size": "100m"
    },
    "storage-driver": "overlay2"
  }
  EOF
  $ sudo mkdir -p /etc/systemd/system/docker.service.d
  $ sudo systemctl daemon-reload
  $ sudo systemctl restart docker
  ```

- 잘 안되서 슈퍼계정 들어간 상태에서 실행했음 `#`





---





### 2. Kubernetes

#### Kubernetes 설치

- Version : 1.14



#### 신뢰할 수 있는 APT 키 추가

```bash
$ sudo apt install apt-transport-https
$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
```



#### Repository 추가 및 Kubernetes 설치

```bash
# Repository 추가
$ cat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF
$ sudo apt-get update
$ sudo apt-get install -y kubelet kubeadm kubectl
# 패키지가 자동으로 설치, 업그레이드, 제거되지 않도록 hold함.
$ sudo apt-mark hold kubelet kubeadm kubectl
# 설치 완료 확인
$ kubeadm version
$ kubelet --version
$ kubectl version
```



#### kube-router 설치를 위해

```
# sysctl net.bridge.bridge-nf-call-iptables=1
```





#### Master 노드 초기화

- root 계정 접속 :

  ```bash
  sudo passwd root 입력 후 패스워드 설정
  su 명령어로 root 계정 연결
  # 현 keti
  ```

- 초기화 시 사용할 Pod Network 에 따라 코드가 달라질 수 있다

- [Pod Network 사용 방법 및 초기화 코드 확인 페이지](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network)

- 해당 명령어를 실행하고 제대로 마스터노드가 셋업되면 아래와 같은 메시지를 출력한다

- **설치 시 사용한 애드온은 Flannel으로 "10.244.0.0/16" 네트워크 대역을 사용한다**

```bash
# Master 노드 생성 명령어
$ sudo kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.100.5

# 셋업 성공 메시지
[init] Using Kubernetes version: v1.16.3
[preflight] Running pre-flight checks
	[WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at <https://kubernetes.io/docs/setup/cri/>
	[WARNING SystemVerification]: this Docker version is not on the list of validated versions: 19.03.4. Latest validated version: 18.09
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
...
...
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy
Your Kubernetes control-plane has initialized successfully!
To start using your cluster, you need to run the following as a regular user:
  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config
You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  <https://kubernetes.io/docs/concepts/cluster-administration/addons/>
Then you can join any number of worker nodes by running the following on each as root:
kubeadm join 192.168.99.102:6443 --token fnbiji.5wob1hu12wdtnmyr \
    --discovery-token-ca-cert-hash sha256:701d4da5cbf67347595e0653b31a7f6625a130de72ad8881a108093afd06188b
```



#### **여기서 자꾸 에러가 떠서 진행이 안되엇다

- 도커와 kubernetes간 cgroup 이 일치하지 않아서 그럼, `systemd`로 변경했는데도 안되서 아래 내용을 추가해봤다
- 아래 명령어 실행하여 해당 내용 추가

```
- 10-kobeadm.conf 내용 변경
# vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf 

- 아래 내용 추가
Environment=”KUBELET_CGROUP_ARGS=–cgroup-driver=systemd”

```





#### kubectl 권한설정(*꼭 root 에서 나와서 설정해준다!)

- 다음 명령어 실행로 `kubectl`권한 설정

  ```bash
  $ mkdir -p $HOME/.kube
  $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  $ sudo chown $(id -u):$(id -g) $HOME/.kube/config
  ```

- `admin.conf` 파일은 `kubeadm init` 명령어 수행했을 때 생성

- 즉, Master 노드에서만 `kubectl` 명령어를 사용가능하며, 다른 노드에서 사용하고 싶을때는 admin.conf 파일을 복사해서 사용한다

- 

#### Pod 네트워크 구성 - Flannel

- Pod 이 서로 통신할 수 있도록 Network Add-on(여기선 Flannel)을 설치한다

```bash
$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
```



#### **설치 확인

- 아래 명령어로 잘 구성되었는지 확인한다

```bash
# 확인 명령어
kubectl get nodes
## 응답
NAME         STATUS     ROLES     AGE       VERSION
kubemaster   NotReady   master    4m        v1.18.6
```

- 아직 NotReady 상태이다
- 만약 이 때, <mark>에러메시지</mark>가 뜨면 아래처럼 해결해준다

```bash
## Error message. 1
Unable to connect to the server: x509: certificate signed by unkown authority~~

# 해결 방법
export KUBECONFIG=/etc/kubernetes/admin.conf


## Error message. 2 (자주 뜨는 에러!) 
<localhost:6443> was refuesed~~~~~~~~

# 해결 방법 : 그냥 기다리면 되거나 아래
sudo -i
swappoff -a
sudo vi /etc/fstab # 여기서 swapfile  관련된거 주석처리해주기!!(꼭)
strace -eopenat kubectl version
```

##### **Master Node 세팅 완료**



---



#### Worker Nodes 세팅

- Docker 설치 후 Master 와 동일한 방법으로 Kubernetes 설치 후 **Join**
- Worker Node 에서 아래 명령어 실행

```bash
# 이 명령어는 Master 세팅 시 맨 아래 출력됨
kubeadm join 192.168.100.5:6443 --token 813ucf.89bo9j9mfk6pm4vx \
    --discovery-token-ca-cert-hash sha256:7f1758ca4cfd117cda27099644cbe4ef672559a47ab33dce8dd87ddf2e8bea1c
```



#### **설치 실패 시 초기화 방법

```
- docker 초기화

$ docker rm -f `docker ps -aq`

$ docker volume rm `docker volume ls -q`
$ umount /var/lib/docker/volumes
# rm -rf /var/lib/docker/

# systemctl restart docker 


- k8s 초기화

# kubeadm reset

$ systemctl restart kubelet



# iptables에 있는 데이터를 청소하기 위해

$ reboot 
```



---

#### Kubernetes 명령어 [(공식문서)](https://kubernetes.io/ko/docs/reference/kubectl/cheatsheet/)

- [참고](https://judo0179.tistory.com/66)

#### kuberctl 명령어

- 쿠버네티스는 `kubectl` 이라는 CLI 명령어를 통해서 쿠버네티스 및 클러스터 관리, 디버그 및 트러블 슈팅을 할 수 있다
- 기본적 명령어는 기본적으로 아래와 같다

```bash
$ kubectl [command] [type] [name] [flag]
```

- `command` : 자원에서 실행하려는 동작
  - `create` : 생성
  - `get` : 정보 가져오기
  - `describe` : 자세한 상태 정보
  - `delete` : 삭제
- `type` : 자원 타입
  - `pod` : Pod
  - `service` : 서비스(네트워크)
- `name` : 자원 이름
- `flag` : 옵션



#### kubectl 기본 사용법

- `run` : 특정 이미지를 가지고 pod을 생성

  ```bash
  $ kubectl run [Pod Name] --generator=[Repolication Controller 지정] --image=[사용할 이미지] --port=[포트 정보]
  ```

- pod의 서비스 생성

  ```bash
  $ kubectl expose pod echoserver --type=NodePort
  ```

- kubeconfig 환경 변수 확인

  ```bash
  $ kubectl config view
  ```

- 서비스 확인

  ```bash
  $ kubectl get svc
  ```

- deployment 확인

  ```bash
  $ kubect get deployment
  ```

- Nodes 확인 : `kubectl get nodes`

- pods 확인 : `kubectl get pods --all-namespaces`

- 구성요소 확인 : `kubectl get componentstatuses`

- Node 삭제 : 마스터에서 `kubectl delete node $NODENAME`

- config 확인(scheduler, c-manager 확인) : `kubeadm config print init-defaults`

- Node 세부사항 확인 : `kubectl --kubeconfig=$KUBE_CONFIG describe node $NODENAME (이것도 똑같은데..? kubectl describe node $NODENAME)`

- 토큰 리스트 보기 : `kubeadm token list`

- 토큰 생성하기 : `kubeadm token create`

- deployment(배포) 명령어로 배포 : `kubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1`

- deployment 확인 : `kubectl get deployments`

- pod 확인 : `kubectl get pods -o wide`

- 워커노드에서 컨테이너 통신 시도 : `curl http://10.244.x.x:8080`





---





### 3. Prometheus 



#### yaml 파일 작성하여 설치

##### 제일 먼저 namespace 를 생성한다

```
$ kubectl create ns monitoring
```



#### yaml 파일 작성

- `vim` 명령어를 사용해 작성해 준다

#### Cluster Role 을 작성한다

- 프로메테우스 컨테이너가 k8s API 에 접근할 수 있는 권한을 주기위해 Cluster Role 을 설정해주고 ClusterRoleBinding 해준다
- 생성된 Cluster Role 은 monitoring namespace 의 기본 서비스 어카운트와 연동되어 권한을 부여한다

```yaml
# prometheus-cluster-role.yaml

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: prometheus
  namespace: monitoring
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: default
  namespace: monitoring
```



#### Configmap

- 프로메테우스가 기동되려면 환경설정파일이 필요한데 해당 환경 설정 파일을 작성

- data 밑에 `prometheus.rules` 와 `prometheus.yml` 를 각각 정의였음

  (다른예제에선 따로 하는 경우도 있었음)

  - **prometheus.rules** : 수집한 지표에 대한 알람 조건을 지정하여 특정 조건이 되면 AlertManager로 알람을 보낼 수 있음
  - **prometheus.yml** : 수집할 지표(metric)의 종류와 수집 주기등을 기입

```yaml
# prometheus-config-map.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-server-conf
  labels:
    name: prometheus-server-conf
  namespace: monitoring
data:
# prometheus.rules 정의부분
  prometheus.rules: |-
    groups:
    - name: container memory alert
      rules:
      - alert: container memory usage rate is very high( > 55%)
        expr: sum(container_memory_working_set_bytes{pod!="", name=""})/ sum (kube_node_status_allocatable_memory_bytes) * 100 > 55
        for: 1m
        labels:
          severity: fatal
        annotations:
          summary: High Memory Usage on 
          identifier: ""
          description: " Memory Usage: "
    - name: container CPU alert
      rules:
      - alert: container CPU usage rate is very high( > 10%)
        expr: sum (rate (container_cpu_usage_seconds_total{pod!=""}[1m])) / sum (machine_cpu_cores) * 100 > 10
        for: 1m
        labels:
          severity: fatal
        annotations:
          summary: High Cpu Usage
          
# prometheus.yml 정의부분
  prometheus.yml: |-
    global:
      scrape_interval: 5s
      evaluation_interval: 5s
    rule_files:
      - /etc/prometheus/prometheus.rules
    alerting:
      alertmanagers:
      - scheme: http
        static_configs:
        - targets:
          - "alertmanager.monitoring.svc:9093"

    scrape_configs:
      - job_name: 'kubernetes-apiservers'

        kubernetes_sd_configs:
        - role: endpoints
        scheme: https

        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https

      - job_name: 'kubernetes-nodes'

        scheme: https

        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        kubernetes_sd_configs:
        - role: node

        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics


      - job_name: 'kubernetes-pods'

        kubernetes_sd_configs:
        - role: pod

        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: kubernetes_pod_name

      - job_name: 'kube-state-metrics'
        static_configs:
          - targets: ['kube-state-metrics.kube-system.svc.cluster.local:8080']

      - job_name: 'kubernetes-cadvisor'

        scheme: https

        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        kubernetes_sd_configs:
        - role: node

        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

      - job_name: 'kubernetes-service-endpoints'

        kubernetes_sd_configs:
        - role: endpoints

        relabel_configs:
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
          action: replace
          target_label: __scheme__
          regex: (https?)
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
          action: replace
          target_label: __address__
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_service_name]
          action: replace
          target_label: kubernetes_name
```



#### deployment

- 프로메테우스의 이미지를 담은 pod을 담은 depolyment controller

```yaml
# prometheus-deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus-deployment
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus-server
  template:
    metadata:
      labels:
        app: prometheus-server
    spec:
      containers:
        - name: prometheus
          image: prom/prometheus:latest
          args:
            - "--config.file=/etc/prometheus/prometheus.yml"
            - "--storage.tsdb.path=/prometheus/"
          ports:
            - containerPort: 9090
          volumeMounts:
            - name: prometheus-config-volume
              mountPath: /etc/prometheus/
            - name: prometheus-storage-volume
              mountPath: /prometheus/
      volumes:
        - name: prometheus-config-volume
          configMap:
            defaultMode: 420
            name: prometheus-server-conf

        - name: prometheus-storage-volume
          emptyDir: {}
```



#### node exporter

- 프로메테우스가 수집하는 metric 은 쿠버네티스에서 기본적으로 제공하는 system metric 만 수집하는 것이 아니고 그 외의 것들도 수집하기 때문에 수집역할을 하는 에이전트를 따로 두어야 함
- 그 역할을 해주는게 **node-exporter** 이고 각 노드에 하나씩 띄워야 하므로 <mark>**daemonSet**</mark>으로 구성해준다

```yaml
# prometheus-node-exporter.yaml

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
  namespace: monitoring
  labels:
    k8s-app: node-exporter
spec:
  selector:
    matchLabels:
      k8s-app: node-exporter
  template:
    metadata:
      labels:
        k8s-app: node-exporter
    spec:
      containers:
      - image: prom/node-exporter
        name: node-exporter
        ports:
        - containerPort: 9100
          protocol: TCP
          name: http
---
apiVersion: v1
kind: Service
metadata:
  labels:
    k8s-app: node-exporter
  name: node-exporter
  namespace: kube-system
spec:
  ports:
  - name: http
    port: 9100
    nodePort: 31672
    protocol: TCP
  type: NodePort
  selector:
    k8s-app: node-exporter
```



#### Service

- 프로메테우스 pod을 외부로 노출시키는 서비스를 구성
- 여기서 port 번호는 8080 (grafana 에서도 사용)
- nodePort  는 30003으로 본인이 임의 지정해준다

```yaml
# prometheus-svc.yaml

apiVersion: v1
kind: Service
metadata:
  name: prometheus-service
  namespace: monitoring
  annotations:
      prometheus.io/scrape: 'true'
      prometheus.io/port:   '9090'
spec:
  selector:
    app: prometheus-server
  type: NodePort
  ports:
    - port: 8080
      targetPort: 9090
      nodePort: 30003
```





#### yaml 파일 배포

```
$ kubectl apply -f prometheus-cluster-role.yaml
$ kubectl apply -f prometheus-config-map.yaml
$ kubectl apply -f prometheus-deployment.yaml
$ kubectl apply -f prometheus-node-exporter.yaml
$ kubectl apply -f prometheus-svc.yaml
```



- 배포된 것 확인 : 

```
$ kubectl get pod -n monitoring

NAME                                     READY   STATUS    RESTARTS   AGE
node-exporter-99w2v                      1/1     Running   0          18s
node-exporter-f9q7f                      1/1     Running   0          18s
prometheus-deployment-7bcb5ff899-h4rb7   1/1     Running   0          65s
```





#### Browser 에서 Prometheus Web UI로 접근(확인만)

- [localhost]:30003 으로 접근 가능 (30003은 위 service.yaml에서 지정해주었음)
- Target 에서 kube-state-metrics (0/1)으로 아직 올라가지 않은 것을 볼 수 있는데 올려줘야 한다 (kube-state-metrics는 k8s클러스 내 오브젝트(pod..)에 대한 지표를 생성하는 서비스)



#### kube-state-metrics 배포 위한 yaml 작성

#### ClusterRole, ClusterRoleBinding

```yaml
# kube-state-cluster-role.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kube-state-metrics
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kube-state-metrics
subjects:
- kind: ServiceAccount
  name: kube-state-metrics
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kube-state-metrics
rules:
- apiGroups:
  - ""
  resources: ["configmaps", "secrets", "nodes", "pods", "services", "resourcequotas", "replicationcontrollers", "limitranges", "persistentvolumeclaims", "persistentvolumes", "namespaces", "endpoints"]
  verbs: ["list","watch"]
- apiGroups:
  - extensions
  resources: ["daemonsets", "deployments", "replicasets", "ingresses"]
  verbs: ["list", "watch"]
- apiGroups:
  - apps
  resources: ["statefulsets", "daemonsets", "deployments", "replicasets"]
  verbs: ["list", "watch"]
- apiGroups:
  - batch
  resources: ["cronjobs", "jobs"]
  verbs: ["list", "watch"]
- apiGroups:
  - autoscaling
  resources: ["horizontalpodautoscalers"]
  verbs: ["list", "watch"]
- apiGroups:
  - authentication.k8s.io
  resources: ["tokenreviews"]
  verbs: ["create"]
- apiGroups:
  - authorization.k8s.io
  resources: ["subjectaccessreviews"]
  verbs: ["create"]
- apiGroups:
  - policy
  resources: ["poddisruptionbudgets"]
  verbs: ["list", "watch"]
- apiGroups:
  - certificates.k8s.io
  resources: ["certificatesigningrequests"]
  verbs: ["list", "watch"]
- apiGroups:
  - storage.k8s.io
  resources: ["storageclasses", "volumeattachments"]
  verbs: ["list", "watch"]
- apiGroups:
  - admissionregistration.k8s.io
  resources: ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"]
  verbs: ["list", "watch"]
- apiGroups:
  - networking.k8s.io
  resources: ["networkpolicies"]
  verbs: ["list", "watch"]
```



#### ServiceAccount 생성

```yaml
# kube-state-svcaccount.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  name: kube-state-metrics
  namespace: kube-system
```



#### cube-state-metrics의 deployment 구성

```yaml
# kube-state-deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: kube-state-metrics
  name: kube-state-metrics
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kube-state-metrics
  template:
    metadata:
      labels:
        app: kube-state-metrics
    spec:
      containers:
      - image: quay.io/coreos/kube-state-metrics:v1.8.0
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 5
          timeoutSeconds: 5
        name: kube-state-metrics
        ports:
        - containerPort: 8080
          name: http-metrics
        - containerPort: 8081
          name: telemetry
        readinessProbe:
          httpGet:
            path: /
            port: 8081
          initialDelaySeconds: 5
          timeoutSeconds: 5
      nodeSelector:
        kubernetes.io/os: linux
      serviceAccountName: kube-state-metrics
```



#### kube-state-metrics의 서비스 생성

```yaml
# kube-state-svc.yaml

apiVersion: v1
kind: Service
metadata:
  labels:
    app: kube-state-metrics
  name: kube-state-metrics
  namespace: kube-system
spec:
  clusterIP: None
  ports:
  - name: http-metrics
    port: 8080
    targetPort: http-metrics
  - name: telemetry
    port: 8081
    targetPort: telemetry
  selector:
    app: kube-state-metrics
```



#### 배포

```
$ kubectl apply -f kube-state-cluster-role.yaml
$ kubectl apply -f kube-state-deployment.yaml
$ kubectl apply -f kube-state-svcaccount.yaml
$ kubectl apply -f kube-state-svc.yaml
```



#### 확인

```
$ kubectl get pod -n kube-system

NAME                                       READY   STATUS    RESTARTS   AGE
...
kube-state-metrics-59bd4d9d-nbfrq          1/1     Running   0          50s
```

- 다시 Browser UI 를 확인하면 정상실행 되는것을 확인할 수 있다.





---





### 4. Grafana



#### yaml 파일 작성/배포하여 pod과 svc 생성

- 여기서 nodePort : 30004 중요!!

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      name: grafana
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:latest
        ports:
        - name: grafana
          containerPort: 3000
        env:
        - name: GF_SERVER_HTTP_PORT
          value: "3000"
        - name: GF_AUTH_BASIC_ENABLED
          value: "false"
        - name: GF_AUTH_ANONYMOUS_ENABLED
          value: "true"
        - name: GF_AUTH_ANONYMOUS_ORG_ROLE
          value: Admin
        - name: GF_SERVER_ROOT_URL
          value: /
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
  annotations:
      prometheus.io/scrape: 'true'
      prometheus.io/port:   '3000'
spec:
  selector:
    app: grafana
  type: NodePort
  ports:
    - port: 3000
      targetPort: 3000
      nodePort: 30004
```



- 작성 후 배포 및 pod 확인

```bash
$ kubectl apply -f grafana.yaml

$ kubectl get pod -n monitoring
NAME                                     READY   STATUS    RESTARTS   AGE
grafana-799c99855d-kxhkm                 1/1     Running   0          16s
node-exporter-99w2v                      1/1     Running   0          66m
node-exporter-f9q7f                      1/1     Running   0          66m
prometheus-deployment-7bcb5ff899-h4rb7   1/1     Running   0          67m
```



- `localhost:30004` 로 Grafana 접속 가능!



#### Grafana 작동

1. datasource 추가

   - Add data source 로 이동 
   - Prometheus 선택
   - 연동할 프로메테우스 정보 기입, url 은 서비스의 ip 참고하여 적어주면 된다

   ```bash
   $ kubectl get svc -n monitoring
   
   NAME                 TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
   grafana              NodePort   10.101.152.163   <none>        3000:30004/TCP   6m43s
   prometheus-service   NodePort   10.101.196.111   <none>        8080:30003/TCP   73m
   ```

   - 여기서 `Save & Test` 버튼 눌렀을 때 "Data source is working" 메시지가 뜨면 됨

2. Dashboard 추가

   - Grafana Homepage -> Dashboard -> "kubernetes" 검색 후, 마음에드는 Dashboard 선택 하고  copy id 룰 눌러 대시보드의 id 복사
   - Garafana UI 로 돌아와서 `Import` 
   - 입력된 datasource 인 prometheus (이름은 본인이 저장한 것으로 나온다)를 넣어주면 완료





---







## App 및 배포과정

- manager 폴더는 viewer 앱을 제어하는 앱이 포함된 폴더이다
- viewer 폴더는 카메라를 사용하여 보여주는 앱이 포함된 폴더이다



### 순서

1. manager, viewer 폴더 다운로드 
2. 각 폴더의 도커이미지를 빌드 해준다(Dockerfile 로 배포)
3. manager 폴더에서 manager app 배포
4. viewer 폴더에서 cam1-1, cam1-2 배포